---
description: Python ile internet, web Ã¼zerinden veri alma, Ã§ekme (data grab, web grab)
---

# ğŸ§² Ä°nternet Ãœzerinden Veri Ã‡ekme

## ğŸ’¨ URL'den Veri Alma

Veri almanÄ±n en hÄ±zlÄ± ve basit yolu

```python
import urllib.request
contents = urllib.request.urlopen("http://example.com/foo/bar").read()

# Encoding iÅŸlemi iÃ§in (https://stackoverflow.com/a/17615424/9770490)
encoding = "utf-8"
contents = contents.decode(encoding)
```

## ğŸ†” Web KimliÄŸi `UserAgent` Ayarlama

* BazÄ± web siteleri, isteklerin nereden geldiÄŸini bilmeden hareket edemezler.&#x20;
* Bu sebeple isteÄŸi detaylandÄ±rmamÄ±z gerekmektedir.
* `UserAgent` ile hangi tarayÄ±cÄ±dan ve bilgisayardan baÄŸlandÄ±ÄŸÄ±mÄ±zÄ± belli ederiz

> `HTML` alanÄ±na baÄŸlantÄ±yÄ± yazÄ±n, `pd.read_html(html)` ÅŸeklinde kullanÄ±n

```python
from urllib.request import urlopen, Request

HTML = "" # Ã–rn: https://en.wikipedia.org/

headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}
reg_url = HTML
req = Request(url=reg_url, headers=headers) 
html = urlopen(req).read() # Pandas iÃ§in kullanÄ±lacak html objesi
```

{% hint style="info" %}
â€ğŸ§™â€â™‚ DetaylÄ± bilgi iÃ§in  ["\[Python\]\[Crawler\]â€œHTTP Error 403: Forbiddenâ€](https://medium.com/@speedforcerun/python-crawler-http-error-403-forbidden-1623ae9ba0f) alanÄ±na bakabilirsin.
{% endhint %}

## ğŸ§ TarayÄ±cÄ± Ãœzerinden Veriyi Bulma

* CTRL + SHIFT + C kÄ±sayolu ile aradÄ±ÄŸÄ±nÄ±z elemanÄ± ona tÄ±klayarak seÃ§in
* Elements ekranÄ±ndan aÃ§Ä±lan satÄ±ra saÄŸ tÄ±klayÄ±n ve Copy â†’ Copy selector deyin
* Gelen metni bir notepad gibi bir yere kaydedin

![](<../.gitbook/assets/temel-veri-cekme-islemi1 (1) (1) (1).png>)

![](<../.gitbook/assets/temel-veri-cekme-islemi2 (1).png>)

## ğŸ Python Kodu ile Veriyi Ã‡ekme

* `pip install beautifulsoup4` komutu ile html verilerini iÅŸleme paketi olan `bs4` paketini indirin
* `pip install requests` ile html isteklerini yÃ¶netme paketi olan `requests` paketini indirin
* Daha Ã¶nceden kopyaladÄ±ÄŸÄ±nÄ±z **selector** verisini ve veriyi aldÄ±ÄŸÄ±nÄ±z url bilgisini sÄ±rasÄ±yla `SELECTOR` ve `URL` objelerine atayÄ±n
* Ä°lk olarak kendimizi tanÄ±ttÄ±ÄŸÄ±mÄ±z `headers` verileri ile `GET` isteÄŸi atÄ±p, iÃ§eriÄŸi alÄ±yoruz ve ardÄ±ndan `soup` objemiz ile istediÄŸim **selector** ile elemanÄ± alÄ±yoruz

```python
import requests
from bs4 import BeautifulSoup

SELECTOR = "#answer-24801950 > div > div.votecell.post-layout--left > div > div.js-vote-count.grid--cell.fc-black-500.fs-title.grid.fd-column.ai-center"
URL = "https://stackoverflow.com/questions/24801548/how-to-use-css-selectors-to-retrieve-specific-links-lying-in-some-class-using-be"

html = requests.get(
    URL,
    headers={
        'User-Agent':
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.58',
    }
).text.encode("utf-8")
soup = BeautifulSoup(html, "html.parser")
selected_element = soup.select_one(SELECTOR)
```

## ğŸ“… Tablo Verisi Alma

* Web siteleri Ã¼zerindeki tablolarÄ± Ã§ekmek iÃ§in `pd.read_html` kullanÄ±lÄ±r
* TÃ¼m tablo verileri arasÄ±nda `0`, `1` ... deÄŸerleri ile gezinebiliriz.

```python
import pandas as pd
import json
df = pd.read_html('https://en.wikipedia.org/w/index.php?title=Fortune_Global_500&oldid=855890446', header=0)[1]
fortune_500 = json.loads(df.to_json(orient="records"))
df
```

![](../.gitbook/assets/data\_crowling\_csv.png)

```python
df_list = pd.read_html("https://en.wikipedia.org/w/index.php?title=Automotive_industry&oldid=875776152", header=0)
car_totals = json.loads(df_list[1].to_json(orient="records"))
car_by_man = json.loads(df_list[3].to_json(orient='records'))
```

![](../.gitbook/assets/data\_crowling\_csv2.png)

## ğŸ‘®â€â™‚ï¸ Verilerin SaÄŸlamasÄ± Gereken Ã–zellikler

* GÃ¼nlÃ¼k hayatta veriler istediÄŸimiz kadar basit olmaz, bunlar Ã¼zerinde iÅŸlemler yaparak uygun hale getiririz
* Tek tablodan oluÅŸan basit veya baÄŸlantÄ±lÄ± bir kaÃ§ tablodan oluÅŸan
  * FarklÄ± veriler iÃ§in _mapping_ ile veri tipleri birbirine benzetilir
* Kolay analiz edilebilir formatta olan
* Makine Ã¶ÄŸrenimine sokulabilecek veriler
* DÃ¼ÅŸÃ¼k karmaÅŸÄ±klÄ±ÄŸa sahip
* YÃ¼ksek boyutlu veriler iÃ§in optimizasyon
